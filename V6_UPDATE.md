# V6 Hierarchical Bayesian Update

**Date**: 2025-10-04  
**Status**: ‚úÖ Dependencies installed and tested

---

## What's New in V6

### Hierarchical Bayesian Approach
V6 represents a fundamental shift from point estimation to **full Bayesian inference** using PyMC's NUTS sampler.

**Key Differences from V5**:
- **V5**: Point estimates with Adam optimizer (frequentist)
- **V6**: Full posterior distributions with MCMC (Bayesian)

### Implementation Details

**Sampling Framework**: PyMC 5.x with NUTS (No-U-Turn Sampler)
- Explores full posterior geometry
- Provides uncertainty quantification
- Captures parameter correlations
- Diagnostic tools via ArviZ

**Hierarchical Structure**:
```
Population Level (Hyperparameters)
    ‚îú‚îÄ‚îÄ Œº_D0, œÉ_D0     ‚Üí Population mean/std for D‚ÇÄ
    ‚îú‚îÄ‚îÄ Œº_Œª, œÉ_Œª       ‚Üí Population mean/std for Œª (log-normal)
    ‚îú‚îÄ‚îÄ Œº_Œ∫, œÉ_Œ∫       ‚Üí Population mean/std for Œ∫ (log-normal)
    ‚îî‚îÄ‚îÄ Œº_Œ≥, œÉ_Œ≥       ‚Üí Population mean/std for Œ≥

Participant Level
    ‚îú‚îÄ‚îÄ D0[i] ~ N(Œº_D0, œÉ_D0)      for i=1...N
    ‚îú‚îÄ‚îÄ Œª[i] ~ LogN(Œº_Œª, œÉ_Œª)
    ‚îú‚îÄ‚îÄ Œ∫[i] ~ LogN(Œº_Œ∫, œÉ_Œ∫)
    ‚îî‚îÄ‚îÄ Œ≥[i] ~ N(Œº_Œ≥, œÉ_Œ≥)
```

---

## Dependencies Added

### New Packages Installed
```
pymc>=5.0           # Probabilistic programming framework
arviz>=0.22         # Bayesian diagnostics and visualization
pytensor>=2.31      # Backend for PyMC (auto-installed)
pandas>=2.3         # Data handling (dependency)
matplotlib>=3.10    # Plotting (dependency)
xarray>=2025.9      # Multi-dimensional arrays (dependency)
```

### Full Dependency Tree
```
pymc 5.25.1
‚îú‚îÄ‚îÄ arviz 0.22.0
‚îú‚îÄ‚îÄ pytensor 2.31.7
‚îú‚îÄ‚îÄ pandas 2.3.3
‚îú‚îÄ‚îÄ matplotlib 3.10.6
‚îî‚îÄ‚îÄ xarray 2025.9.1
```

---

## Running V6

### Basic Usage

```bash
# Quick test (5 simulations, 18 participants, very fast)
python simulations/parameter_recovery_v6_hierarchical.py \
    --n-sim 5 --n-participants 18 --draws 1000 --tune 1000

# Standard run (10 simulations, default settings)
python simulations/parameter_recovery_v6_hierarchical.py \
    --n-sim 10 --n-participants 35 --chains 2

# Production run (50 simulations, longer MCMC)
python simulations/parameter_recovery_v6_hierarchical.py \
    --n-sim 50 --n-participants 35 --draws 2000 --tune 2000 --chains 4
```

### Command-Line Options

| Option | Default | Description |
|--------|---------|-------------|
| `--n-sim` | 5 | Number of simulations to run |
| `--n-participants` | 18 | Participants per simulation |
| `--draws` | 1000 | Posterior samples per chain |
| `--tune` | 1000 | Tuning/warmup steps |
| `--chains` | 2 | Number of MCMC chains |
| `--seed` | 12345 | Random seed |

---

## Expected Runtime

**Per Simulation** (NUTS is computationally intensive):
- **18 participants, 1000 draws, 2 chains**: ~5-10 minutes
- **35 participants, 1000 draws, 2 chains**: ~10-20 minutes  
- **35 participants, 2000 draws, 4 chains**: ~30-60 minutes

**Full Runs**:
- 5 simulations (quick test): ~30 minutes
- 10 simulations: ~2 hours
- 50 simulations: ~10-15 hours (recommend overnight)

---

## Advantages Over V5

### 1. **Full Uncertainty Quantification**
- Not just point estimates, but entire posterior distributions
- Credible intervals for each parameter
- Parameter correlation structure

### 2. **Hierarchical Shrinkage**
- Information pooling across participants
- More stable estimates for individual participants
- Better handling of outliers

### 3. **Diagnostic Tools**
- Trace plots (convergence visualization)
- R-hat statistics (chain convergence)
- Effective sample size
- Posterior predictive checks

### 4. **No Tuning Required**
- NUTS automatically adapts step size
- No manual learning rate/optimizer tuning
- Robust across different scenarios

---

## Disadvantages / Trade-offs

### 1. **Computational Cost**
- 10-50x slower than V5 per simulation
- Requires more memory (storing MCMC traces)
- Best suited for smaller-scale validation

### 2. **Complexity**
- Harder to debug if MCMC doesn't converge
- Requires understanding of Bayesian diagnostics
- More dependencies (PyMC ecosystem)

### 3. **Interpretation**
- Results are distributions, not single values
- Need to decide: posterior mean? median? MAP?
- Requires Bayesian reasoning

---

## When to Use Each Version

### Use V5 (Adam Optimizer)
- ‚úÖ Large-scale validation (500+ simulations)
- ‚úÖ Quick parameter recovery checks
- ‚úÖ GPU acceleration needed
- ‚úÖ Production/automated pipelines

### Use V6 (Bayesian MCMC)
- ‚úÖ Detailed uncertainty quantification
- ‚úÖ Model comparison / diagnostics
- ‚úÖ Publication-quality posteriors
- ‚úÖ Small/medium scale validation (5-50 sims)

---

## Requirements Update

**Updated**: `requirements.txt` now includes:
```
# Hierarchical Bayesian modeling (v6)
pymc>=5.0
arviz>=0.22
```

**Installation**:
```bash
# In existing venv
pip install pymc arviz

# Or fresh install
pip install -r requirements.txt
```

---

## Validation Status

| Version | Method | Status | Best Use Case |
|---------|--------|--------|---------------|
| v4 | JAX/GPU | ‚úÖ Validated (500 sims) | Large-scale GPU runs |
| v5 | NumPy/Adam | ‚úÖ Tested (3 sims) | Fast CPU validation |
| v6 | PyMC/NUTS | ‚úÖ Ready | Uncertainty quantification |

---

## Next Steps

1. **Test v6 with small run**:
   ```bash
   python simulations/parameter_recovery_v6_hierarchical.py --n-sim 2 --n-participants 18
   ```

2. **Compare v5 vs v6 results** (interesting research question!)

3. **Use v6 for final paper**:
   - Run 10-20 simulations with full posteriors
   - Report credible intervals, not just point estimates
   - Include posterior predictive checks

---

## Files Modified/Added

**Modified**:
- `requirements.txt` - Added PyMC and ArviZ

**Added**:
- `simulations/parameter_recovery_v6_hierarchical.py` - New Bayesian version

**Environment**:
- All dependencies installed in `.venv`
- Tested import successfully

---

## Summary

‚úÖ **V6 ready to use** - Full Bayesian hierarchical modeling now available  
‚úÖ **Dependencies installed** - PyMC 5.25.1, ArviZ 0.22.0  
‚úÖ **Tested** - Imports successful, ready for first run  
‚è≥ **Recommended**: Start with `--n-sim 2` to test pipeline  

**Paradigm shift**: From point estimates ‚Üí full posterior distributions üéØ

